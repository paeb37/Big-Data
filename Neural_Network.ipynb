{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h-WHBtR3tfRI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import csv\n",
        "import talos\n",
        "from talos.utils import lr_normalizer\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.activations import relu, elu\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from talos.utils import hidden_layers\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_df(dataframe, filename): # save a dataframe to a csv file\n",
        "    # writing to csv file\n",
        "    with open(filename, 'w') as csvfile: \n",
        "        # creating a csv writer object\n",
        "        csvwriter = csv.writer(csvfile,lineterminator='\\n')\n",
        "\n",
        "        # writing the fields\n",
        "        csvwriter.writerow(dataframe.columns) \n",
        "\n",
        "        # writing the data rows \n",
        "        csvwriter.writerows(np.array(dataframe))\n",
        "\n",
        "# Load and prepare the dataset\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data Science Hackathon/yellow_cab_data.csv') # Read in data\n",
        "\n",
        "# convert N to 0, Y to 1\n",
        "\n",
        "df['store_and_fwd_flag'] = df['store_and_fwd_flag'].replace('N', 0)\n",
        "df['store_and_fwd_flag'] = df['store_and_fwd_flag'].replace('Y', 1)\n",
        "\n",
        "# save_df(df,'/content/drive/MyDrive/Data Science Hackathon/test_1.csv')"
      ],
      "metadata": {
        "id": "uRtrwY2Ytu75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(df.columns)\n",
        "\n",
        "row_index = 0\n",
        "\n",
        "while row_index < len(df): # convert each date into a float\n",
        "    for col in ['tpep_pickup_datetime', 'tpep_dropoff_datetime']:\n",
        "        date = df[col].iloc[row_index]\n",
        "        date = date.split() # date splits into 2022-01-01 and 00:27:45\n",
        "        first_half = date[0].split('-') # 2022-01-01 splits into 2022, 01, 01\n",
        "        year = int(first_half[0]) # 2022\n",
        "        month = int(first_half[1]) # 01\n",
        "        day = int(first_half[2]) # 01\n",
        "\n",
        "        second_half = date[1].split(':') # 00:27:45 splits into 00, 27, 45\n",
        "        hour = int(second_half[0]) # 00\n",
        "        min = int(second_half[1]) # 27\n",
        "        sec = int(second_half[2]) # 45\n",
        "\n",
        "        date_float = (year - 2022) * 365.25 + (month - 1) * 30.437 + (day - 1) + (hour / 24.0) + (min / (24.0 * 60)) + (sec / (24.0 * 3600))\n",
        "        df.at[row_index, col] = date_float\n",
        "\n",
        "    row_index += 1\n",
        "\n",
        "# save_df(df,'/content/drive/MyDrive/Data Science Hackathon/test_2.csv')\n",
        "\n",
        "# to create new predictions, we have to split the dataset roughly 50 to 50\n",
        "# take the first half and split it into training and test\n",
        "# then make predictions on the second half of the dataset\n",
        "\n",
        "'''\n",
        "mid = int(len(df) / 2)\n",
        "X = df['fare_amount'].iloc[:mid]\n",
        "Y = df['fare_amount'].iloc[mid:]\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "'''\n",
        "\n",
        "mid = int(len(df) / 2)\n",
        "X_tot = df.drop('fare_amount',axis=1)\n",
        "X_tot = np.asarray(X_tot).astype('float32')\n",
        "Y_tot = df['fare_amount']\n",
        "\n",
        "X = X_tot[0:mid]\n",
        "Y = Y_tot[0:mid]\n",
        "\n",
        "X_generate = X_tot[mid:]\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmZDY6mWtvWd",
        "outputId": "828c6e5d-3106-4816-d7b8-363dc51b347c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(75000, 18)\n",
            "(75000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset into train, validation, test\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
        "\n",
        "params = {'learning_rate': 0.1, # learning rate [0.1,0.3,0.5]\n",
        "          'first_hidden_layer':8, # neurons in first layer\n",
        "          'second_hidden_layer':8, # neurons in second layer\n",
        "          'third_hidden_layer':8, # neurons in third layer [8,16,32,64]\n",
        "          'batch_size': 30, # batch size [5,10,50]\n",
        "          'epochs': 150, # number of epochs\n",
        "          'dropout': 0.3, # percentage of input that is ignored\n",
        "          'optimizer': Adam, # methods of gradient descent\n",
        "          'losses': mean_squared_error, # cost function\n",
        "          'activation':relu, # maps the layer's input to output\n",
        "          'last_activation': None,\n",
        "          'weight_regulizer': None,\n",
        "          'emb_output_dims': None}\n",
        "\n",
        "'''\n",
        "optimizer = dp_optimizer.DPGradientDescentGaussianOptimizer(\n",
        "          l2_norm_clip=FLAGS.l2_norm_clip,\n",
        "          noise_multiplier=FLAGS.noise_multiplier,\n",
        "          num_microbatches=FLAGS.microbatches,\n",
        "          learning_rate=FLAGS.learning_rate)\n",
        "'''\n",
        "\n",
        "if True:\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    # input layer and 1st hidden layer\n",
        "    model.add(Dense(units=params['first_hidden_layer'], input_dim=train_X.shape[1], \n",
        "                    activation=params['activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # hidden layer\n",
        "    model.add(Dense(units=params['second_hidden_layer'], activation=params['activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # hidden layer \n",
        "    model.add(Dense(units=params['third_hidden_layer'], activation=params['activation'],\n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # output layer\n",
        "    model.add(Dense(units=1, activation=params['last_activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(loss='mean_squared_error',\n",
        "                  optimizer=params['optimizer'](lr=lr_normalizer(params['learning_rate'],params['optimizer'])),\n",
        "                  metrics=keras.metrics.mean_squared_error)\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(x=train_X,\n",
        "                        y=train_Y, \n",
        "                        batch_size=params['batch_size'],\n",
        "                        epochs=params['epochs'],\n",
        "                        verbose=0)\n",
        "    \n",
        "    Y_generate = model.predict(X_generate)\n",
        "\n",
        "'''\n",
        "TESTING TALOS HYPERPARAMETER OPTIMIZATION\n",
        "\n",
        "def keras_model(x_train,y_train,x_val,y_val,params):\n",
        "\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    # input layer and 1st hidden layer\n",
        "    model.add(Dense(units=params['first_hidden_layer'], input_dim=1, \n",
        "                    activation=params['activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # hidden layer\n",
        "    model.add(Dense(units=params['second_hidden_layer'], activation=params['activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # hidden layer \n",
        "    model.add(Dense(units=params['third_hidden_layer'], activation=params['activation'],\n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # output layer\n",
        "    model.add(Dense(units=1, activation=params['last_activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(loss='mean_squared_error',\n",
        "                  optimizer=params['optimizer'](lr=lr_normalizer(params['lr'],params['optimizer'])),\n",
        "                  metrics=keras.metrics.mean_squared_error)\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(x=x_train,\n",
        "                        y=y_train, \n",
        "                        validation_data=(x_val,y_val),\n",
        "                        batch_size=params['batch_size'],\n",
        "                        epochs=params['epochs'],\n",
        "                        verbose=0)\n",
        "\n",
        "    return history,model\n",
        "\n",
        "# set parameter space\n",
        "\n",
        "p = {'lr': [0.1, 0.3, 0.5], # learning rate [0.1,0.3,0.5]\n",
        "     'first_hidden_layer':[8, 16, 32, 64, 128], # neurons in first layer\n",
        "     'second_hidden_layer':[8, 16, 32, 64], # neurons in second layer\n",
        "     'third_hidden_layer':[8, 16, 32, 64], # neurons in third layer [8,16,32,64]\n",
        "     'batch_size': (2, 30, 10), # batch size [5,10,50]\n",
        "     'epochs': [150], # number of epochs\n",
        "     'dropout': [0.3, 0.5], # percentage of input that is ignored\n",
        "     'optimizer': [Adam], # methods of gradient descent\n",
        "     'losses': [mean_squared_error], # cost function\n",
        "     'activation':[relu], # maps the layer's input to output\n",
        "     'last_activation': [None],\n",
        "     'weight_regulizer':[None],\n",
        "     'emb_output_dims': [None]}\n",
        "\n",
        "# run the experiment\n",
        "scan_object = talos.Scan(x=train_X,\n",
        "                         y=train_Y,\n",
        "                         val_split = 0.25,\n",
        "                         model=keras_model,\n",
        "                         params=p,\n",
        "                         experiment_name='Talos_Optimization',\n",
        "                         fraction_limit=.01)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "HbVzfcQRtizF",
        "outputId": "e3fd1a5a-8da5-4275-d17f-c9002679f71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2344/2344 [==============================] - 3s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef keras_model(x_train,y_train,x_val,y_val,params):\\n\\n    # create model\\n    model = Sequential()\\n\\n    # input layer and 1st hidden layer\\n    model.add(Dense(units=params['first_hidden_layer'], input_dim=1, \\n                    activation=params['activation'], \\n                    kernel_initializer='normal'))\\n\\n    # dropout layer\\n    model.add(Dropout(params['dropout']))\\n\\n    # hidden layer\\n    model.add(Dense(units=params['second_hidden_layer'], activation=params['activation'], \\n                    kernel_initializer='normal'))\\n\\n    # dropout layer\\n    model.add(Dropout(params['dropout']))\\n\\n    # hidden layer \\n    model.add(Dense(units=params['third_hidden_layer'], activation=params['activation'],\\n                    kernel_initializer='normal'))\\n\\n    # dropout layer\\n    model.add(Dropout(params['dropout']))\\n\\n    # output layer\\n    model.add(Dense(units=1, activation=params['last_activation'], \\n                    kernel_initializer='normal'))\\n\\n    # compile model\\n    model.compile(loss='mean_squared_error',\\n                  optimizer=params['optimizer'](lr=lr_normalizer(params['lr'],params['optimizer'])),\\n                  metrics=keras.metrics.mean_squared_error)\\n\\n    # train model\\n    history = model.fit(x=x_train,\\n                        y=y_train, \\n                        validation_data=(x_val,y_val),\\n                        batch_size=params['batch_size'],\\n                        epochs=params['epochs'],\\n                        verbose=0)\\n\\n    return history,model\\n\\n# set the parameter space\\n\\np = {'lr': [0.1, 0.3, 0.5], # learning rate [0.1,0.3,0.5]\\n     'first_hidden_layer':[8, 16, 32, 64, 128], # neurons in first layer\\n     'second_hidden_layer':[8, 16, 32, 64], # neurons in second layer\\n     'third_hidden_layer':[8, 16, 32, 64], # neurons in third layer [8,16,32,64]\\n     'batch_size': (2, 30, 10), # batch size [5,10,50]\\n     'epochs': [150], # number of epochs\\n     'dropout': [0.3, 0.5], # percentage of input that is ignored\\n     'optimizer': [Adam], # methods of gradient descent\\n     'losses': [mean_squared_error], # cost function\\n     'activation':[relu], # maps the layer's input to output\\n     'last_activation': [None],\\n     'weight_regulizer':[None],\\n     'emb_output_dims': [None]}\\n\\n# run the experiment\\nscan_object = talos.Scan(x=train_X,\\n                         y=train_Y,\\n                         val_split = 0.25,\\n                         model=keras_model,\\n                         params=p,\\n                         experiment_name='Talos_Optimization',\\n                         fraction_limit=.01)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import SupportsComplex\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "import math\n",
        "\n",
        "def mean(items):\n",
        "  sum = 0\n",
        "  count = 0\n",
        "  for item in items:\n",
        "    if not math.isnan(item):\n",
        "      sum += item\n",
        "      count += 1\n",
        "  return sum / count\n",
        "\n",
        "def stdev(items):\n",
        "  mean1 = mean(items)\n",
        "  sum = 0\n",
        "  count = 0\n",
        "  for item in items:\n",
        "    if not math.isnan(item):\n",
        "      sum += pow(item-mean1,2)\n",
        "      count += 1\n",
        "  var = sum / count\n",
        "  std = math.sqrt(var)  # standard deviation\n",
        "  return std\n",
        "\n",
        "plt.plot(Y,color='blue')\n",
        "plt.plot(Y_generate,color='orange') # orange is the extrapolated data\n",
        "plt.show()\n",
        "\n",
        "# mean, median, standard deviation, variance\n",
        "Y_generate = pd.DataFrame(Y_generate)\n",
        "\n",
        "# save_df(Y_generate,'/content/drive/MyDrive/Data Science Hackathon/test_3.csv')\n",
        "\n",
        "mean_data = mean(Y)\n",
        "mean_gen = mean(Y_generate.values)\n",
        "\n",
        "print(\"Mean in Data: \" + str(mean_data))\n",
        "print(\"Mean in Generated: \" + str(mean_gen[0]))\n",
        "\n",
        "median_data = statistics.median(Y)\n",
        "median_gen = statistics.median(Y_generate.values)\n",
        "\n",
        "print(\"Median in Data: \" + str(median_data))\n",
        "print(\"Median in Generated: \" + str(median_gen[0]))\n",
        "\n",
        "stdev_data = statistics.stdev(Y)\n",
        "stdev_gen = stdev(Y_generate.values)\n",
        "\n",
        "print(\"Standard Deviation in Data: \" + str(stdev_data))\n",
        "print(\"Standard Deviation in Generated: \" + str(stdev_gen))\n",
        "\n",
        "var_data = statistics.stdev(Y) * statistics.stdev(Y)\n",
        "var_gen = stdev(Y_generate.values) * stdev(Y_generate.values)\n",
        "\n",
        "print(\"Variance in Data: \" + str(var_data))\n",
        "print(\"Variance in Generated: \" + str(var_gen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "8UECZUVzBxok",
        "outputId": "93d51bc1-37d1-49df-ec65-5c0e11dc501e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean in Data: 12.858080533333265\n",
            "Mean in Generated: 12.117890877981871\n",
            "Median in Data: 9.0\n",
            "Median in Generated: 7.3224316\n",
            "Standard Deviation in Data: 13.107143091242827\n",
            "Standard Deviation in Generated: 10.09883646877305\n",
            "Variance in Data: 171.79720001431457\n",
            "Variance in Generated: 101.98649802302052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install tensorflow-privacy\n",
        "\n",
        "from tensorflow_privacy.privacy.optimizers import dp_optimizer"
      ],
      "metadata": {
        "id": "J1ElFgVOTmHX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOW TESTING THE TIP AMT\n",
        "\n",
        "def save_df(dataframe, filename): # save a dataframe to a csv file\n",
        "    # writing to csv file\n",
        "    with open(filename, 'w') as csvfile: \n",
        "        # creating a csv writer object\n",
        "        csvwriter = csv.writer(csvfile,lineterminator='\\n')\n",
        "\n",
        "        # writing the fields\n",
        "        csvwriter.writerow(dataframe.columns) \n",
        "\n",
        "        # writing the data rows \n",
        "        csvwriter.writerows(np.array(dataframe))\n",
        "\n",
        "# Load and prepare the dataset\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data Science Hackathon/yellow_cab_data.csv') # Read in data\n",
        "\n",
        "# convert N to 0, Y to 1\n",
        "\n",
        "df['store_and_fwd_flag'] = df['store_and_fwd_flag'].replace('N', 0)\n",
        "df['store_and_fwd_flag'] = df['store_and_fwd_flag'].replace('Y', 1)\n",
        "\n",
        "# save_df(df,'/content/drive/MyDrive/Data Science Hackathon/test_1.csv')"
      ],
      "metadata": {
        "id": "EDdyyiNhRdJ-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(df.columns)\n",
        "\n",
        "row_index = 0\n",
        "\n",
        "while row_index < len(df): # convert each date into a float\n",
        "    for col in ['tpep_pickup_datetime', 'tpep_dropoff_datetime']:\n",
        "        date = df[col].iloc[row_index]\n",
        "        date = date.split() # date splits into 2022-01-01 and 00:27:45\n",
        "        first_half = date[0].split('-') # 2022-01-01 splits into 2022, 01, 01\n",
        "        year = int(first_half[0]) # 2022\n",
        "        month = int(first_half[1]) # 01\n",
        "        day = int(first_half[2]) # 01\n",
        "\n",
        "        second_half = date[1].split(':') # 00:27:45 splits into 00, 27, 45\n",
        "        hour = int(second_half[0]) # 00\n",
        "        min = int(second_half[1]) # 27\n",
        "        sec = int(second_half[2]) # 45\n",
        "\n",
        "        date_float = (year - 2022) * 365.25 + (month - 1) * 30.437 + (day - 1) + (hour / 24.0) + (min / (24.0 * 60)) + (sec / (24.0 * 3600))\n",
        "        df.at[row_index, col] = date_float\n",
        "\n",
        "    row_index += 1\n",
        "\n",
        "# save_df(df,'/content/drive/MyDrive/Data Science Hackathon/test_2.csv')\n",
        "\n",
        "# might need to convert strings into floats here\n",
        "# to create new predictions, we have to split the dataset roughly 50 to 50\n",
        "# take the first half and split it into training and test\n",
        "# then make predictions on the second half of the dataset\n",
        "\n",
        "'''\n",
        "mid = int(len(df) / 2)\n",
        "X = df['fare_amount'].iloc[:mid]\n",
        "Y = df['fare_amount'].iloc[mid:]\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "'''\n",
        "\n",
        "mid = int(len(df) / 2)\n",
        "X_tot = df.drop('tip_amount',axis=1)\n",
        "X_tot = np.asarray(X_tot).astype('float32')\n",
        "Y_tot = df['tip_amount']\n",
        "\n",
        "X = X_tot[0:mid]\n",
        "Y = Y_tot[0:mid]\n",
        "\n",
        "X_generate = X_tot[mid:]\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "p-_6X8gkST0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e540c364-e613-48e4-8533-4e0ee2e90583"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(75000, 18)\n",
            "(75000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset into train, validation, test\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
        "\n",
        "params = {'learning_rate': 0.1, # learning rate [0.1,0.3,0.5]\n",
        "          'first_hidden_layer':8, # neurons in first layer\n",
        "          'second_hidden_layer':8, # neurons in second layer\n",
        "          'third_hidden_layer':8, # neurons in third layer [8,16,32,64]\n",
        "          'batch_size': 30, # batch size [5,10,50]\n",
        "          'epochs': 150, # number of epochs\n",
        "          'dropout': 0.3, # percentage of input that is ignored\n",
        "          'optimizer': Adam, # methods of gradient descent\n",
        "          'losses': mean_squared_error, # cost function\n",
        "          'activation':relu, # maps the layer's input to output\n",
        "          'last_activation': None,\n",
        "          'weight_regulizer': None,\n",
        "          'emb_output_dims': None}\n",
        "\n",
        "if True:\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    # input layer and 1st hidden layer\n",
        "    model.add(Dense(units=params['first_hidden_layer'], input_dim=train_X.shape[1], \n",
        "                    activation=params['activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # hidden layer\n",
        "    model.add(Dense(units=params['second_hidden_layer'], activation=params['activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # hidden layer \n",
        "    model.add(Dense(units=params['third_hidden_layer'], activation=params['activation'],\n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # output layer\n",
        "    model.add(Dense(units=1, activation=params['last_activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(loss='mean_squared_error',\n",
        "                  optimizer=params['optimizer'](lr=lr_normalizer(params['learning_rate'],params['optimizer'])),\n",
        "                  metrics=keras.metrics.mean_squared_error)\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(x=train_X,\n",
        "                        y=train_Y, \n",
        "                        batch_size=params['batch_size'],\n",
        "                        epochs=params['epochs'],\n",
        "                        verbose=1)\n",
        "    \n",
        "    Y_generate = model.predict(X_generate)"
      ],
      "metadata": {
        "id": "v5q2bjNTSZdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34ccc79-1f64-4cfc-df33-18cf1967969f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "2000/2000 [==============================] - 6s 2ms/step - loss: 6.4596 - mean_squared_error: 6.4596\n",
            "Epoch 2/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 5.5501 - mean_squared_error: 5.5501\n",
            "Epoch 3/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 4.5533 - mean_squared_error: 4.5533\n",
            "Epoch 4/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 3.4301 - mean_squared_error: 3.4301\n",
            "Epoch 5/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 3.3844 - mean_squared_error: 3.3844\n",
            "Epoch 6/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.7498 - mean_squared_error: 2.7498\n",
            "Epoch 7/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.6032 - mean_squared_error: 2.6032\n",
            "Epoch 8/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.4004 - mean_squared_error: 2.4004\n",
            "Epoch 9/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 2.4098 - mean_squared_error: 2.4098\n",
            "Epoch 10/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.9849 - mean_squared_error: 2.9849\n",
            "Epoch 11/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.4045 - mean_squared_error: 2.4045\n",
            "Epoch 12/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.7881 - mean_squared_error: 2.7881\n",
            "Epoch 13/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 2.2439 - mean_squared_error: 2.2439\n",
            "Epoch 14/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.1503 - mean_squared_error: 2.1503\n",
            "Epoch 15/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.1827 - mean_squared_error: 2.1827\n",
            "Epoch 16/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.8111 - mean_squared_error: 2.8111\n",
            "Epoch 17/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 2.2392 - mean_squared_error: 2.2392\n",
            "Epoch 18/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 2.1840 - mean_squared_error: 2.1840\n",
            "Epoch 19/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.1887 - mean_squared_error: 2.1887\n",
            "Epoch 20/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.0769 - mean_squared_error: 2.0769\n",
            "Epoch 21/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 2.0476 - mean_squared_error: 2.0476\n",
            "Epoch 22/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 2.0348 - mean_squared_error: 2.0348\n",
            "Epoch 23/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.2235 - mean_squared_error: 2.2235\n",
            "Epoch 24/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.2091 - mean_squared_error: 2.2091\n",
            "Epoch 25/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.1182 - mean_squared_error: 2.1182\n",
            "Epoch 26/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 2.0062 - mean_squared_error: 2.0062\n",
            "Epoch 27/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.1262 - mean_squared_error: 2.1262\n",
            "Epoch 28/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.0281 - mean_squared_error: 2.0281\n",
            "Epoch 29/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.9868 - mean_squared_error: 1.9868\n",
            "Epoch 30/150\n",
            "2000/2000 [==============================] - 7s 4ms/step - loss: 1.9758 - mean_squared_error: 1.9758\n",
            "Epoch 31/150\n",
            "2000/2000 [==============================] - 7s 3ms/step - loss: 1.9867 - mean_squared_error: 1.9867\n",
            "Epoch 32/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.0176 - mean_squared_error: 2.0176\n",
            "Epoch 33/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.1279 - mean_squared_error: 2.1279\n",
            "Epoch 34/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 2.0189 - mean_squared_error: 2.0189\n",
            "Epoch 35/150\n",
            "2000/2000 [==============================] - 11s 5ms/step - loss: 1.9863 - mean_squared_error: 1.9863\n",
            "Epoch 36/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.9943 - mean_squared_error: 1.9943\n",
            "Epoch 37/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.9682 - mean_squared_error: 1.9682\n",
            "Epoch 38/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.8809 - mean_squared_error: 1.8809\n",
            "Epoch 39/150\n",
            "2000/2000 [==============================] - 8s 4ms/step - loss: 2.0019 - mean_squared_error: 2.0019\n",
            "Epoch 40/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.8800 - mean_squared_error: 1.8800\n",
            "Epoch 41/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.9226 - mean_squared_error: 1.9226\n",
            "Epoch 42/150\n",
            "2000/2000 [==============================] - 9s 4ms/step - loss: 1.9353 - mean_squared_error: 1.9353\n",
            "Epoch 43/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.2181 - mean_squared_error: 2.2181\n",
            "Epoch 44/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.9141 - mean_squared_error: 1.9141\n",
            "Epoch 45/150\n",
            "2000/2000 [==============================] - 7s 3ms/step - loss: 4.5090 - mean_squared_error: 4.5090\n",
            "Epoch 46/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.8474 - mean_squared_error: 1.8474\n",
            "Epoch 47/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.0332 - mean_squared_error: 2.0332\n",
            "Epoch 48/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.9726 - mean_squared_error: 1.9726\n",
            "Epoch 49/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.9964 - mean_squared_error: 1.9964\n",
            "Epoch 50/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.8830 - mean_squared_error: 1.8830\n",
            "Epoch 51/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.9701 - mean_squared_error: 1.9701\n",
            "Epoch 52/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7891 - mean_squared_error: 1.7891\n",
            "Epoch 53/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.8988 - mean_squared_error: 1.8988\n",
            "Epoch 54/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.8608 - mean_squared_error: 1.8608\n",
            "Epoch 55/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8637 - mean_squared_error: 1.8637\n",
            "Epoch 56/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.9427 - mean_squared_error: 2.9427\n",
            "Epoch 57/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.9943 - mean_squared_error: 1.9943\n",
            "Epoch 58/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 3.9972 - mean_squared_error: 3.9972\n",
            "Epoch 59/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.9548 - mean_squared_error: 1.9548\n",
            "Epoch 60/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8515 - mean_squared_error: 1.8515\n",
            "Epoch 61/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.8573 - mean_squared_error: 1.8573\n",
            "Epoch 62/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.8911 - mean_squared_error: 1.8911\n",
            "Epoch 63/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8778 - mean_squared_error: 1.8778\n",
            "Epoch 64/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8602 - mean_squared_error: 1.8602\n",
            "Epoch 65/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8850 - mean_squared_error: 1.8850\n",
            "Epoch 66/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.7647 - mean_squared_error: 1.7647\n",
            "Epoch 67/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8546 - mean_squared_error: 1.8546\n",
            "Epoch 68/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8386 - mean_squared_error: 1.8386\n",
            "Epoch 69/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8165 - mean_squared_error: 1.8165\n",
            "Epoch 70/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.8332 - mean_squared_error: 1.8332\n",
            "Epoch 71/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.7796 - mean_squared_error: 1.7796\n",
            "Epoch 72/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8568 - mean_squared_error: 1.8568\n",
            "Epoch 73/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 2.2804 - mean_squared_error: 2.2804\n",
            "Epoch 74/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.8277 - mean_squared_error: 1.8277\n",
            "Epoch 75/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.7998 - mean_squared_error: 1.7998\n",
            "Epoch 76/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8222 - mean_squared_error: 1.8222\n",
            "Epoch 77/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7321 - mean_squared_error: 1.7321\n",
            "Epoch 78/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7704 - mean_squared_error: 1.7704\n",
            "Epoch 79/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.7475 - mean_squared_error: 1.7475\n",
            "Epoch 80/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8302 - mean_squared_error: 1.8302\n",
            "Epoch 81/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8055 - mean_squared_error: 1.8055\n",
            "Epoch 82/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7309 - mean_squared_error: 1.7309\n",
            "Epoch 83/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.7405 - mean_squared_error: 1.7405\n",
            "Epoch 84/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.8391 - mean_squared_error: 1.8391\n",
            "Epoch 85/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6997 - mean_squared_error: 1.6997\n",
            "Epoch 86/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.8194 - mean_squared_error: 1.8194\n",
            "Epoch 87/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.6993 - mean_squared_error: 1.6993\n",
            "Epoch 88/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7409 - mean_squared_error: 1.7409\n",
            "Epoch 89/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7893 - mean_squared_error: 1.7893\n",
            "Epoch 90/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7628 - mean_squared_error: 1.7628\n",
            "Epoch 91/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.7235 - mean_squared_error: 1.7235\n",
            "Epoch 92/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.7550 - mean_squared_error: 1.7550\n",
            "Epoch 93/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8287 - mean_squared_error: 1.8287\n",
            "Epoch 94/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7402 - mean_squared_error: 1.7402\n",
            "Epoch 95/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.7298 - mean_squared_error: 1.7298\n",
            "Epoch 96/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.6861 - mean_squared_error: 1.6861\n",
            "Epoch 97/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6818 - mean_squared_error: 1.6818\n",
            "Epoch 98/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7850 - mean_squared_error: 1.7850\n",
            "Epoch 99/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7769 - mean_squared_error: 1.7769\n",
            "Epoch 100/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.7070 - mean_squared_error: 1.7070\n",
            "Epoch 101/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7343 - mean_squared_error: 1.7343\n",
            "Epoch 102/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6877 - mean_squared_error: 1.6877\n",
            "Epoch 103/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7020 - mean_squared_error: 1.7020\n",
            "Epoch 104/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.6819 - mean_squared_error: 1.6819\n",
            "Epoch 105/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.7631 - mean_squared_error: 1.7631\n",
            "Epoch 106/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6929 - mean_squared_error: 1.6929\n",
            "Epoch 107/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8119 - mean_squared_error: 1.8119\n",
            "Epoch 108/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.6759 - mean_squared_error: 1.6759\n",
            "Epoch 109/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.6519 - mean_squared_error: 1.6519\n",
            "Epoch 110/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6463 - mean_squared_error: 1.6463\n",
            "Epoch 111/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7690 - mean_squared_error: 1.7690\n",
            "Epoch 112/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6849 - mean_squared_error: 1.6849\n",
            "Epoch 113/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.6825 - mean_squared_error: 1.6825\n",
            "Epoch 114/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.6593 - mean_squared_error: 1.6593\n",
            "Epoch 115/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6557 - mean_squared_error: 1.6557\n",
            "Epoch 116/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6795 - mean_squared_error: 1.6795\n",
            "Epoch 117/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.7420 - mean_squared_error: 1.7420\n",
            "Epoch 118/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.6911 - mean_squared_error: 1.6911\n",
            "Epoch 119/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7231 - mean_squared_error: 1.7231\n",
            "Epoch 120/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7826 - mean_squared_error: 1.7826\n",
            "Epoch 121/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.7263 - mean_squared_error: 1.7263\n",
            "Epoch 122/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.6614 - mean_squared_error: 1.6614\n",
            "Epoch 123/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7290 - mean_squared_error: 1.7290\n",
            "Epoch 124/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8014 - mean_squared_error: 1.8014\n",
            "Epoch 125/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7143 - mean_squared_error: 1.7143\n",
            "Epoch 126/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.7263 - mean_squared_error: 1.7263\n",
            "Epoch 127/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.6249 - mean_squared_error: 1.6249\n",
            "Epoch 128/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6825 - mean_squared_error: 1.6825\n",
            "Epoch 129/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6650 - mean_squared_error: 1.6650\n",
            "Epoch 130/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.6460 - mean_squared_error: 1.6460\n",
            "Epoch 131/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.6854 - mean_squared_error: 1.6854\n",
            "Epoch 132/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6901 - mean_squared_error: 1.6901\n",
            "Epoch 133/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7381 - mean_squared_error: 1.7381\n",
            "Epoch 134/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.7202 - mean_squared_error: 1.7202\n",
            "Epoch 135/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.7533 - mean_squared_error: 1.7533\n",
            "Epoch 136/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6884 - mean_squared_error: 1.6884\n",
            "Epoch 137/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7706 - mean_squared_error: 1.7706\n",
            "Epoch 138/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7598 - mean_squared_error: 1.7598\n",
            "Epoch 139/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.7324 - mean_squared_error: 1.7324\n",
            "Epoch 140/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8893 - mean_squared_error: 1.8893\n",
            "Epoch 141/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8999 - mean_squared_error: 1.8999\n",
            "Epoch 142/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8463 - mean_squared_error: 1.8463\n",
            "Epoch 143/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.6673 - mean_squared_error: 1.6673\n",
            "Epoch 144/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 1.7194 - mean_squared_error: 1.7194\n",
            "Epoch 145/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6762 - mean_squared_error: 1.6762\n",
            "Epoch 146/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7162 - mean_squared_error: 1.7162\n",
            "Epoch 147/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.6800 - mean_squared_error: 1.6800\n",
            "Epoch 148/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 1.6311 - mean_squared_error: 1.6311\n",
            "Epoch 149/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6693 - mean_squared_error: 1.6693\n",
            "Epoch 150/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6875 - mean_squared_error: 1.6875\n",
            "2344/2344 [==============================] - 4s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import SupportsComplex\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "import math\n",
        "\n",
        "def mean(items):\n",
        "  sum = 0\n",
        "  count = 0\n",
        "  for item in items:\n",
        "    if not math.isnan(item):\n",
        "      sum += item\n",
        "      count += 1\n",
        "  return sum / count\n",
        "\n",
        "def stdev(items):\n",
        "  mean1 = mean(items)\n",
        "  sum = 0\n",
        "  count = 0\n",
        "  for item in items:\n",
        "    if not math.isnan(item):\n",
        "      sum += pow(item-mean1,2)\n",
        "      count += 1\n",
        "  var = sum / count\n",
        "  std = math.sqrt(var)  # standard deviation\n",
        "  return std\n",
        "\n",
        "plt.plot(Y[0:70000],color='blue')\n",
        "plt.plot(Y_generate[0:70000],color='orange') # orange is the extrapolated data\n",
        "plt.show()\n",
        "\n",
        "# mean, median, standard deviation, variance\n",
        "Y_generate = pd.DataFrame(Y_generate)\n",
        "\n",
        "# save_df(Y_generate,'/content/drive/MyDrive/Data Science Hackathon/test_3.csv')\n",
        "\n",
        "mean_data = mean(Y)\n",
        "mean_gen = mean(Y_generate.values)\n",
        "\n",
        "print(\"Mean in Data: \" + str(mean_data))\n",
        "print(\"Mean in Generated: \" + str(mean_gen[0]))\n",
        "\n",
        "median_data = statistics.median(Y)\n",
        "median_gen = statistics.median(Y_generate.values)\n",
        "\n",
        "print(\"Median in Data: \" + str(median_data))\n",
        "print(\"Median in Generated: \" + str(median_gen[0]))\n",
        "\n",
        "stdev_data = statistics.stdev(Y)\n",
        "stdev_gen = stdev(Y_generate.values)\n",
        "\n",
        "print(\"Standard Deviation in Data: \" + str(stdev_data))\n",
        "print(\"Standard Deviation in Generated: \" + str(stdev_gen))\n",
        "\n",
        "var_data = statistics.stdev(Y) * statistics.stdev(Y)\n",
        "var_gen = stdev(Y_generate.values) * stdev(Y_generate.values)\n",
        "\n",
        "print(\"Variance in Data: \" + str(var_data))\n",
        "print(\"Variance in Generated: \" + str(var_gen))"
      ],
      "metadata": {
        "id": "OduxUw2rSZ0z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "2abb4f71-0bf9-4da3-df6e-f05d91a918a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean in Data: 2.367622266666619\n",
            "Mean in Generated: 1.8967060655552257\n",
            "Median in Data: 2.0\n",
            "Median in Generated: 1.7668502\n",
            "Standard Deviation in Data: 2.796618665829092\n",
            "Standard Deviation in Generated: 1.1479778517018713\n",
            "Variance in Data: 7.82107596206369\n",
            "Variance in Generated: 1.3178531479980435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PRINT THE CORRELATION\n",
        "\n",
        "tempName = \"tip_amount\"\n",
        "\n",
        "col2 = Y[0:70000]\n",
        "\n",
        "print(Y_generate[0:70000].corrwith(col2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE8pxYe0ZNQo",
        "outputId": "d5337321-caa5-48f3-810a-07c3b34cb264"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0   -0.003076\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOW TESTING THE PAYMENT_TYPE\n",
        "\n",
        "def save_df(dataframe, filename): # save a dataframe to a csv file\n",
        "    # writing to csv file\n",
        "    with open(filename, 'w') as csvfile: \n",
        "        # creating a csv writer object\n",
        "        csvwriter = csv.writer(csvfile,lineterminator='\\n')\n",
        "\n",
        "        # writing the fields\n",
        "        csvwriter.writerow(dataframe.columns) \n",
        "\n",
        "        # writing the data rows \n",
        "        csvwriter.writerows(np.array(dataframe))\n",
        "\n",
        "# Load and prepare the dataset\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data Science Hackathon/yellow_cab_data.csv') # Read in data\n",
        "\n",
        "# convert N to 0, Y to 1\n",
        "\n",
        "df['store_and_fwd_flag'] = df['store_and_fwd_flag'].replace('N', 0)\n",
        "df['store_and_fwd_flag'] = df['store_and_fwd_flag'].replace('Y', 1)\n",
        "\n",
        "# save_df(df,'/content/drive/MyDrive/Data Science Hackathon/test_1.csv')"
      ],
      "metadata": {
        "id": "RdgOwwjzdpv_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(df.columns)\n",
        "\n",
        "row_index = 0\n",
        "\n",
        "while row_index < len(df): # convert each date into a float\n",
        "    for col in ['tpep_pickup_datetime', 'tpep_dropoff_datetime']:\n",
        "        date = df[col].iloc[row_index]\n",
        "        date = date.split() # date splits into 2022-01-01 and 00:27:45\n",
        "        first_half = date[0].split('-') # 2022-01-01 splits into 2022, 01, 01\n",
        "        year = int(first_half[0]) # 2022\n",
        "        month = int(first_half[1]) # 01\n",
        "        day = int(first_half[2]) # 01\n",
        "\n",
        "        second_half = date[1].split(':') # 00:27:45 splits into 00, 27, 45\n",
        "        hour = int(second_half[0]) # 00\n",
        "        min = int(second_half[1]) # 27\n",
        "        sec = int(second_half[2]) # 45\n",
        "\n",
        "        date_float = (year - 2022) * 365.25 + (month - 1) * 30.437 + (day - 1) + (hour / 24.0) + (min / (24.0 * 60)) + (sec / (24.0 * 3600))\n",
        "        df.at[row_index, col] = date_float\n",
        "\n",
        "    row_index += 1\n",
        "\n",
        "# save_df(df,'/content/drive/MyDrive/Data Science Hackathon/test_2.csv')\n",
        "\n",
        "'''\n",
        "mid = int(len(df) / 2)\n",
        "X = df['fare_amount'].iloc[:mid]\n",
        "Y = df['fare_amount'].iloc[mid:]\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "'''\n",
        "\n",
        "mid = int(len(df) / 2)\n",
        "X_tot = df.drop('payment_type',axis=1)\n",
        "X_tot = np.asarray(X_tot).astype('float32')\n",
        "Y_tot = df['payment_type']\n",
        "\n",
        "X = X_tot[0:mid]\n",
        "Y = Y_tot[0:mid]\n",
        "\n",
        "X_generate = X_tot[mid:]\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTuSOGZ0d0Qo",
        "outputId": "9ca3ffea-1cee-4d73-80c6-13d74765b010"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(75000, 18)\n",
            "(75000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset into train, validation, test\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
        "\n",
        "params = {'learning_rate': 0.1, # learning rate [0.1,0.3,0.5]\n",
        "          'first_hidden_layer':8, # neurons in first layer\n",
        "          'second_hidden_layer':8, # neurons in second layer\n",
        "          'third_hidden_layer':8, # neurons in third layer [8,16,32,64]\n",
        "          'batch_size': 30, # batch size [5,10,50]\n",
        "          'epochs': 150, # number of epochs\n",
        "          'dropout': 0.3, # percentage of input that is ignored\n",
        "          'optimizer': Adam, # methods of gradient descent\n",
        "          'losses': mean_squared_error, # cost function\n",
        "          'activation':relu, # maps the layer's input to output\n",
        "          'last_activation': None,\n",
        "          'weight_regulizer': None,\n",
        "          'emb_output_dims': None}\n",
        "\n",
        "if True:\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    # input layer and 1st hidden layer\n",
        "    model.add(Dense(units=params['first_hidden_layer'], input_dim=train_X.shape[1], \n",
        "                    activation=params['activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # hidden layer\n",
        "    model.add(Dense(units=params['second_hidden_layer'], activation=params['activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # hidden layer \n",
        "    model.add(Dense(units=params['third_hidden_layer'], activation=params['activation'],\n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # dropout layer\n",
        "    model.add(Dropout(params['dropout']))\n",
        "\n",
        "    # output layer\n",
        "    model.add(Dense(units=1, activation=params['last_activation'], \n",
        "                    kernel_initializer='normal'))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(loss='mean_squared_error',\n",
        "                  optimizer=params['optimizer'](lr=lr_normalizer(params['learning_rate'],params['optimizer'])),\n",
        "                  metrics=keras.metrics.mean_squared_error)\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(x=train_X,\n",
        "                        y=train_Y, \n",
        "                        batch_size=params['batch_size'],\n",
        "                        epochs=params['epochs'],\n",
        "                        verbose=1)\n",
        "    \n",
        "    Y_generate = model.predict(X_generate)\n",
        "\n",
        "Y_generate = np.around(Y_generate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drzG5v4Id3M5",
        "outputId": "a5a6ba7d-5236-479a-cf41-226b1ed4f5f4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2746 - mean_squared_error: 0.2746\n",
            "Epoch 2/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1120 - mean_squared_error: 0.1120\n",
            "Epoch 3/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1131 - mean_squared_error: 0.1131\n",
            "Epoch 4/150\n",
            "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0911 - mean_squared_error: 0.0911\n",
            "Epoch 5/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0951 - mean_squared_error: 0.0951\n",
            "Epoch 6/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0933 - mean_squared_error: 0.0933\n",
            "Epoch 7/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.1006 - mean_squared_error: 0.1006\n",
            "Epoch 8/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0888 - mean_squared_error: 0.0888\n",
            "Epoch 9/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0859 - mean_squared_error: 0.0859\n",
            "Epoch 10/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0835 - mean_squared_error: 0.0835\n",
            "Epoch 11/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0866 - mean_squared_error: 0.0866\n",
            "Epoch 12/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0878 - mean_squared_error: 0.0878\n",
            "Epoch 13/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0849 - mean_squared_error: 0.0849\n",
            "Epoch 14/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0825 - mean_squared_error: 0.0825\n",
            "Epoch 15/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0837 - mean_squared_error: 0.0837\n",
            "Epoch 16/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.1011 - mean_squared_error: 0.1011\n",
            "Epoch 17/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0828 - mean_squared_error: 0.0828\n",
            "Epoch 18/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0908 - mean_squared_error: 0.0908\n",
            "Epoch 19/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0807 - mean_squared_error: 0.0807\n",
            "Epoch 20/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0825 - mean_squared_error: 0.0825\n",
            "Epoch 21/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0835 - mean_squared_error: 0.0835\n",
            "Epoch 22/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0826 - mean_squared_error: 0.0826\n",
            "Epoch 23/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0835 - mean_squared_error: 0.0835\n",
            "Epoch 24/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0827 - mean_squared_error: 0.0827\n",
            "Epoch 25/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0843 - mean_squared_error: 0.0843\n",
            "Epoch 26/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0825 - mean_squared_error: 0.0825\n",
            "Epoch 27/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0825 - mean_squared_error: 0.0825\n",
            "Epoch 28/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0824 - mean_squared_error: 0.0824\n",
            "Epoch 29/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0825 - mean_squared_error: 0.0825\n",
            "Epoch 30/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0829 - mean_squared_error: 0.0829\n",
            "Epoch 31/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0855 - mean_squared_error: 0.0855\n",
            "Epoch 32/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0814 - mean_squared_error: 0.0814\n",
            "Epoch 33/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0817 - mean_squared_error: 0.0817\n",
            "Epoch 34/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0822 - mean_squared_error: 0.0822\n",
            "Epoch 35/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0838 - mean_squared_error: 0.0838\n",
            "Epoch 36/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0828 - mean_squared_error: 0.0828\n",
            "Epoch 37/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0823 - mean_squared_error: 0.0823\n",
            "Epoch 38/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0843 - mean_squared_error: 0.0843\n",
            "Epoch 39/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0814 - mean_squared_error: 0.0814\n",
            "Epoch 40/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0835 - mean_squared_error: 0.0835\n",
            "Epoch 41/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0834 - mean_squared_error: 0.0834\n",
            "Epoch 42/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0837 - mean_squared_error: 0.0837\n",
            "Epoch 43/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0838 - mean_squared_error: 0.0838\n",
            "Epoch 44/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0813 - mean_squared_error: 0.0813\n",
            "Epoch 45/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0821 - mean_squared_error: 0.0821\n",
            "Epoch 46/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0824 - mean_squared_error: 0.0824\n",
            "Epoch 47/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0821 - mean_squared_error: 0.0821\n",
            "Epoch 48/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0831 - mean_squared_error: 0.0831\n",
            "Epoch 49/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0815 - mean_squared_error: 0.0815\n",
            "Epoch 50/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0806 - mean_squared_error: 0.0806\n",
            "Epoch 51/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0823 - mean_squared_error: 0.0823\n",
            "Epoch 52/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0831 - mean_squared_error: 0.0831\n",
            "Epoch 53/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0819 - mean_squared_error: 0.0819\n",
            "Epoch 54/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0815 - mean_squared_error: 0.0815\n",
            "Epoch 55/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0862 - mean_squared_error: 0.0862\n",
            "Epoch 56/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0812 - mean_squared_error: 0.0812\n",
            "Epoch 57/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0817 - mean_squared_error: 0.0817\n",
            "Epoch 58/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0810 - mean_squared_error: 0.0810\n",
            "Epoch 59/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0831 - mean_squared_error: 0.0831\n",
            "Epoch 60/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0817 - mean_squared_error: 0.0817\n",
            "Epoch 61/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0814 - mean_squared_error: 0.0814\n",
            "Epoch 62/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0808 - mean_squared_error: 0.0808\n",
            "Epoch 63/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0799 - mean_squared_error: 0.0799\n",
            "Epoch 64/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0816 - mean_squared_error: 0.0816\n",
            "Epoch 65/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0812 - mean_squared_error: 0.0812\n",
            "Epoch 66/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0816 - mean_squared_error: 0.0816\n",
            "Epoch 67/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0810 - mean_squared_error: 0.0810\n",
            "Epoch 68/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0819 - mean_squared_error: 0.0819\n",
            "Epoch 69/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0819 - mean_squared_error: 0.0819\n",
            "Epoch 70/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0812 - mean_squared_error: 0.0812\n",
            "Epoch 71/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.1139 - mean_squared_error: 0.1139\n",
            "Epoch 72/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0816 - mean_squared_error: 0.0816\n",
            "Epoch 73/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0825 - mean_squared_error: 0.0825\n",
            "Epoch 74/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0815 - mean_squared_error: 0.0815\n",
            "Epoch 75/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0921 - mean_squared_error: 0.0921\n",
            "Epoch 76/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0812 - mean_squared_error: 0.0812\n",
            "Epoch 77/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0820 - mean_squared_error: 0.0820\n",
            "Epoch 78/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0817 - mean_squared_error: 0.0817\n",
            "Epoch 79/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0823 - mean_squared_error: 0.0823\n",
            "Epoch 80/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0817 - mean_squared_error: 0.0817\n",
            "Epoch 81/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0828 - mean_squared_error: 0.0828\n",
            "Epoch 82/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0808 - mean_squared_error: 0.0808\n",
            "Epoch 83/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0802 - mean_squared_error: 0.0802\n",
            "Epoch 84/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0947 - mean_squared_error: 0.0947\n",
            "Epoch 85/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0811 - mean_squared_error: 0.0811\n",
            "Epoch 86/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0813 - mean_squared_error: 0.0813\n",
            "Epoch 87/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0821 - mean_squared_error: 0.0821\n",
            "Epoch 88/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0811 - mean_squared_error: 0.0811\n",
            "Epoch 89/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0806 - mean_squared_error: 0.0806\n",
            "Epoch 90/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0811 - mean_squared_error: 0.0811\n",
            "Epoch 91/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0807 - mean_squared_error: 0.0807\n",
            "Epoch 92/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0811 - mean_squared_error: 0.0811\n",
            "Epoch 93/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0837 - mean_squared_error: 0.0837\n",
            "Epoch 94/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0802 - mean_squared_error: 0.0802\n",
            "Epoch 95/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0820 - mean_squared_error: 0.0820\n",
            "Epoch 96/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0799 - mean_squared_error: 0.0799\n",
            "Epoch 97/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0805 - mean_squared_error: 0.0805\n",
            "Epoch 98/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0806 - mean_squared_error: 0.0806\n",
            "Epoch 99/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0808 - mean_squared_error: 0.0808\n",
            "Epoch 100/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0819 - mean_squared_error: 0.0819\n",
            "Epoch 101/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0811 - mean_squared_error: 0.0811\n",
            "Epoch 102/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0805 - mean_squared_error: 0.0805\n",
            "Epoch 103/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0802 - mean_squared_error: 0.0802\n",
            "Epoch 104/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0810 - mean_squared_error: 0.0810\n",
            "Epoch 105/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0816 - mean_squared_error: 0.0816\n",
            "Epoch 106/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0818 - mean_squared_error: 0.0818\n",
            "Epoch 107/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0813 - mean_squared_error: 0.0813\n",
            "Epoch 108/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0809 - mean_squared_error: 0.0809\n",
            "Epoch 109/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0809 - mean_squared_error: 0.0809\n",
            "Epoch 110/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0837 - mean_squared_error: 0.0837\n",
            "Epoch 111/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0805 - mean_squared_error: 0.0805\n",
            "Epoch 112/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0810 - mean_squared_error: 0.0810\n",
            "Epoch 113/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0812 - mean_squared_error: 0.0812\n",
            "Epoch 114/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0813 - mean_squared_error: 0.0813\n",
            "Epoch 115/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0819 - mean_squared_error: 0.0819\n",
            "Epoch 116/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0798 - mean_squared_error: 0.0798\n",
            "Epoch 117/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0813 - mean_squared_error: 0.0813\n",
            "Epoch 118/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0802 - mean_squared_error: 0.0802\n",
            "Epoch 119/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0803 - mean_squared_error: 0.0803\n",
            "Epoch 120/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0823 - mean_squared_error: 0.0823\n",
            "Epoch 121/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0810 - mean_squared_error: 0.0810\n",
            "Epoch 122/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0814 - mean_squared_error: 0.0814\n",
            "Epoch 123/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0803 - mean_squared_error: 0.0803\n",
            "Epoch 124/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0810 - mean_squared_error: 0.0810\n",
            "Epoch 125/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0802 - mean_squared_error: 0.0802\n",
            "Epoch 126/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0816 - mean_squared_error: 0.0816\n",
            "Epoch 127/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0799 - mean_squared_error: 0.0799\n",
            "Epoch 128/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0819 - mean_squared_error: 0.0819\n",
            "Epoch 129/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0823 - mean_squared_error: 0.0823\n",
            "Epoch 130/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0808 - mean_squared_error: 0.0808\n",
            "Epoch 131/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0806 - mean_squared_error: 0.0806\n",
            "Epoch 132/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0797 - mean_squared_error: 0.0797\n",
            "Epoch 133/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0800 - mean_squared_error: 0.0800\n",
            "Epoch 134/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0855 - mean_squared_error: 0.0855\n",
            "Epoch 135/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0800 - mean_squared_error: 0.0800\n",
            "Epoch 136/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0799 - mean_squared_error: 0.0799\n",
            "Epoch 137/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0801 - mean_squared_error: 0.0801\n",
            "Epoch 138/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0794 - mean_squared_error: 0.0794\n",
            "Epoch 139/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0810 - mean_squared_error: 0.0810\n",
            "Epoch 140/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0804 - mean_squared_error: 0.0804\n",
            "Epoch 141/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0813 - mean_squared_error: 0.0813\n",
            "Epoch 142/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0839 - mean_squared_error: 0.0839\n",
            "Epoch 143/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0813 - mean_squared_error: 0.0813\n",
            "Epoch 144/150\n",
            "2000/2000 [==============================] - 5s 3ms/step - loss: 0.0817 - mean_squared_error: 0.0817\n",
            "Epoch 145/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0799 - mean_squared_error: 0.0799\n",
            "Epoch 146/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0828 - mean_squared_error: 0.0828\n",
            "Epoch 147/150\n",
            "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0808 - mean_squared_error: 0.0808\n",
            "Epoch 148/150\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0817 - mean_squared_error: 0.0817\n",
            "Epoch 149/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0816 - mean_squared_error: 0.0816\n",
            "Epoch 150/150\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0797 - mean_squared_error: 0.0797\n",
            "2344/2344 [==============================] - 4s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import SupportsComplex\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "import math\n",
        "\n",
        "def mean(items):\n",
        "  sum = 0\n",
        "  count = 0\n",
        "  for item in items:\n",
        "    if not math.isnan(item):\n",
        "      sum += item\n",
        "      count += 1\n",
        "  return sum / count\n",
        "\n",
        "def stdev(items):\n",
        "  mean1 = mean(items)\n",
        "  sum = 0\n",
        "  count = 0\n",
        "  for item in items:\n",
        "    if not math.isnan(item):\n",
        "      sum += pow(item-mean1,2)\n",
        "      count += 1\n",
        "  var = sum / count\n",
        "  std = math.sqrt(var)  # standard deviation\n",
        "  return std\n",
        "\n",
        "plt.plot(Y[0:70000],color='blue')\n",
        "plt.plot(Y_generate[0:70000],color='orange') # orange is the extrapolated data\n",
        "plt.show()\n",
        "\n",
        "# mean, median, standard deviation, variance\n",
        "Y_generate = pd.DataFrame(Y_generate)\n",
        "\n",
        "# save_df(Y_generate,'/content/drive/MyDrive/Data Science Hackathon/test_3.csv')\n",
        "\n",
        "mean_data = mean(Y)\n",
        "mean_gen = mean(Y_generate.values)\n",
        "\n",
        "print(\"Mean in Data: \" + str(mean_data))\n",
        "print(\"Mean in Generated: \" + str(mean_gen[0]))\n",
        "\n",
        "median_data = statistics.median(Y)\n",
        "median_gen = statistics.median(Y_generate.values)\n",
        "\n",
        "print(\"Median in Data: \" + str(median_data))\n",
        "print(\"Median in Generated: \" + str(median_gen[0]))\n",
        "\n",
        "stdev_data = statistics.stdev(Y)\n",
        "stdev_gen = stdev(Y_generate.values)\n",
        "\n",
        "print(\"Standard Deviation in Data: \" + str(stdev_data))\n",
        "print(\"Standard Deviation in Generated: \" + str(stdev_gen))\n",
        "\n",
        "var_data = statistics.stdev(Y) * statistics.stdev(Y)\n",
        "var_gen = stdev(Y_generate.values) * stdev(Y_generate.values)\n",
        "\n",
        "print(\"Variance in Data: \" + str(var_data))\n",
        "print(\"Variance in Generated: \" + str(var_gen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "rcemW0UPd67s",
        "outputId": "31ada646-ba88-4bd7-9ebe-e99920d62551"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean in Data: 1.2414266666666667\n",
            "Mean in Generated: 1.23244106958526\n",
            "Median in Data: 1.0\n",
            "Median in Generated: 1.0\n",
            "Standard Deviation in Data: 0.46952043329485244\n",
            "Standard Deviation in Generated: 0.4367733860901274\n",
            "Variance in Data: 0.22044943728138597\n",
            "Variance in Generated: 0.19077099079663548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "col = Y_generate[0:70000]\n",
        "\n",
        "df = pd.DataFrame(col)\n",
        "df.value_counts().plot(ax=ax , kind='bar', xlabel='Payment Type', ylabel='Frequency',color='orange')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "3ZDUUZWRhv6P",
        "outputId": "4e88e511-927e-411d-ae8f-5c1acfe0894d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 540x252 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "col = Y[0:70000]\n",
        "\n",
        "df = pd.DataFrame(col)\n",
        "df.value_counts().plot(ax=ax , kind='bar', xlabel='Payment Type', ylabel='Frequency')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "mKBkIJ61iANM",
        "outputId": "9aa4b9ea-883b-4bef-a5f9-a02833ecd5a8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 540x252 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PRINT THE CORRELATION\n",
        "\n",
        "tempName = \"payment_type\"\n",
        "\n",
        "col2 = Y[0:70000]\n",
        "\n",
        "print(Y_generate[0:70000].corrwith(col2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XErv1qURiUS5",
        "outputId": "0f1434b1-10de-4383-a23d-5958ee04a891"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    0.003152\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}